{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defing the appropriate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def PlotPath(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HypothesisFunction(X, theta):\n",
    "    return X.dot(theta)\n",
    "\n",
    "\n",
    "def CostFunction(X, theta, y):\n",
    "    m = y.shape[0]\n",
    "    y_hat = HypothesisFunction(X, theta)\n",
    "    return 1 / m * (y_hat - y).T.dot(y_hat - y)\n",
    "\n",
    "\n",
    "def ErrorFunction(y_hat, y):\n",
    "    m = y.shape[0]\n",
    "    return 1 / m * (y_hat - y).T.dot(y_hat - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BatchGradientDescent(X, y, n_epochs=100, eta=0.1):\n",
    "    \n",
    "    m, n = X.shape\n",
    "    \n",
    "    theta_path, J_path = [], []\n",
    "    \n",
    "    theta = np.random.randn(n, 1)\n",
    "    #J = CostFunction(X, theta, y)\n",
    "    #theta_path.append(theta)\n",
    "    #J_path.append(J)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        y_hat = HypothesisFunction(X, theta)\n",
    "        \n",
    "        gradients = 2 / m * X.T.dot(y_hat - y)\n",
    "        theta -= eta * gradients\n",
    "        J = ErrorFunction(y_hat, y)\n",
    "        \n",
    "        theta_path.append(theta)\n",
    "        J_path.append(J)\n",
    "        \n",
    "    # end for epoch\n",
    "\n",
    "    \n",
    "    return np.array(theta_path), np.array(J_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def StochasticGradientDescent(X, y, n_epochs=100, eta=0.1):\n",
    "    \n",
    "    def learning_schedule(t, t0=1, t1=10):\n",
    "        return t0 / (t + t1)\n",
    "    \n",
    "    m, n = X.shape\n",
    "    \n",
    "    theta_path, J_path = [], []\n",
    "    \n",
    "    theta = np.random.randn(n, 1)\n",
    "    #J = CostFunction(X, theta, y)\n",
    "\n",
    "    t = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(m):\n",
    "            t += 1\n",
    "            rand_index = np.random.randint(m)\n",
    "            xi = X[rand_index:rand_index+1]\n",
    "            yi = y[rand_index:rand_index+1]\n",
    "\n",
    "            yi_hat = HypothesisFunction(xi, theta)\n",
    "\n",
    "            gradients = 2 * xi.T.dot(yi_hat - yi)\n",
    "            eta = learning_schedule(t)\n",
    "            theta = theta - eta * gradients   \n",
    "        # end for i\n",
    "        \n",
    "           \n",
    "        J = ErrorFunction(yi_hat, yi)\n",
    "        theta_path.append(theta)\n",
    "        J_path.append(J)\n",
    "        \n",
    "    \n",
    "    # end for epoch\n",
    "    \n",
    "    return np.array(theta_path), np.array(J_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MiniBatchGradientDescent(X, y, n_epochs=100, eta=0.1, minibatch_size=20):\n",
    "    \n",
    "    def learning_schedule(t, t0=1, t1=10):\n",
    "        return t0 / (t + t1)\n",
    "    \n",
    "    m, n = X.shape\n",
    "    \n",
    "    theta_path, J_path = [], []\n",
    "    \n",
    "    theta = np.random.randn(n, 1)\n",
    "    #J = CostFunction(X, theta, y)\n",
    "\n",
    "    t = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        shuffled_indices = np.random.permutation(m)\n",
    "        X_shuffled = X[shuffled_indices]\n",
    "        y_shuffled = y[shuffled_indices]\n",
    "        \n",
    "        for i in range(0, m, minibatch_size):\n",
    "            t += 1\n",
    "\n",
    "            xi = X_shuffled[i:i+minibatch_size]\n",
    "            yi = y_shuffled[i:i+minibatch_size]\n",
    "\n",
    "            yi_hat = HypothesisFunction(xi, theta)\n",
    "\n",
    "            gradients = 2 / minibatch_size * xi.T.dot(yi_hat - yi)\n",
    "            eta = learning_schedule(t)\n",
    "            theta = theta - eta * gradients\n",
    "            \n",
    "        # end for i\n",
    "        \n",
    "        J = ErrorFunction(yi_hat, yi)\n",
    "        theta_path.append(theta)\n",
    "        J_path.append(J)\n",
    "        \n",
    "        \n",
    "    # end for epoch\n",
    "    \n",
    "    return np.array(theta_path), np.array(J_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defing input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100 # size of the dataset\n",
    "\n",
    "np.random.seed(42)\n",
    "X = 2 * np.random.rand(m, 1)\n",
    "y = 4 + 3 * X + np.random.randn(m,1)\n",
    "\n",
    "X_b = np.c_[np.ones((m, 1)), X]\n",
    "\n",
    "theta_path_bgd, J_path_bgd = BatchGradientDescent(X_b, y)\n",
    "theta_path_sgd, J_path_sgd = StochasticGradientDescent(X_b, y)\n",
    "theta_path_mbg, J_path_mbg = MiniBatchGradientDescent(X_b, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2e4dfa851c8>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(theta_path_bgd[:,0], theta_path_bgd[:,1], label='Batch', \n",
    "         marker='o', lw=1, markersize=4)\n",
    "#plt.plot(theta_path_sgd[:,0], theta_path_sgd[:,1], label='Stochastic',\n",
    "#         marker='s', lw=1, markersize=4)\n",
    "\n",
    "\n",
    "#plt.plot(theta_path_mbg[:,0], theta_path_mbg[:,1], label='Mini-batch',\n",
    "#         marker='v', lw=1, markersize=4)\n",
    "\n",
    "\n",
    "#plt.xlim((1, 4.3))\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The automatic batch size adaptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
